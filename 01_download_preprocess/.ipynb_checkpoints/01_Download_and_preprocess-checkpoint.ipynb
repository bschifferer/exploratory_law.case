{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading all case files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the bulk API from https://case.law/ - https://case.law/bulk/ to downloand and directly extract the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = '<API_KEY>'\n",
    "URL_BULK = 'https://api.case.law/v1/bulk/?body_format=text&filter_type=jurisdiction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processBulk(url_download, filename, access_token = ACCESS_TOKEN):  \n",
    "    # Using wget to download the file\n",
    "    wget_cmd = 'wget --header=\"Authorization: Token ' + ACCESS_TOKEN \\\n",
    "        + '\" -O ../data/01_download/' + filename + ' \"' + url_download + '\"'\n",
    "    # Using unzip to extract\n",
    "    unzip_cmd = 'unzip ../data/01_download/' + filename + ' -d ../data/01_download/ && rm ../data/01_download/' + filename\n",
    "    print(wget_cmd)\n",
    "    print(unzip_cmd)\n",
    "    os.system(wget_cmd)\n",
    "    os.system(unzip_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = headers={'Authorization': 'Token ' + ACCESS_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First request receives an array with download URLs\n",
    "response = requests.get(URL_BULK, headers=header).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in response['results']:\n",
    "    filename = item['file_name']\n",
    "    url_download = item['download_url']\n",
    "    processBulk(url_download, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all files are downloaded and extracted, only relevant variables are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob(\"../data/01_download/*\")\n",
    "# Direct fields\n",
    "fields_direct = ['decision_date', 'docket_number', 'first_page', 'id', 'last_page', 'name' , 'name_abbreviation']\n",
    "# Keywords, which are extracted from the casebody opinion field\n",
    "keywords = [\"dog bite\",\"slip\",\"medical malpractice\",\"drug recall\",\"m&a\",\"antitrust prosecution\",\"asylum\",\"murder\",\"arson\",\"sexual harassment \",\"divorce\",\"real estate\",\"intellectual property\",\"insurance claims\",\"internet\",\"free speech\",\"capital murder\",\"dog\",\"fall\",\"antitrust\",\"sexual\",\"patent\",\"bit\",\"prosecution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_of_occurence(s, s2):\n",
    "    s = s.lower()\n",
    "    s = re.sub('[^0-9a-zA-Z&]+', ' ', s)\n",
    "    s = s.replace('  ', ' ')\n",
    "    return(s.count(s2))\n",
    "\n",
    "def no_of_occurence2(s, s2):\n",
    "    return(s.count(s2))\n",
    "\n",
    "def format_text(s):\n",
    "    # Formatting the text\n",
    "    s = s.lower()\n",
    "    s = re.sub('[^0-9a-zA-Z&]+', ' ', s)\n",
    "    s = s.replace('  ', ' ')\n",
    "    return(s)\n",
    "\n",
    "def processDF(df):\n",
    "    # Extract relevant fields from each jsonLine\n",
    "    df = df.reset_index(drop=True)\n",
    "    df_output = df[fields_direct]\n",
    "    df_volume = json_normalize(df['volume']).add_prefix('volume_')\n",
    "    df_reporter = json_normalize(df['reporter']).add_prefix('reporter_')\n",
    "    df_jurisdiction = json_normalize(df['jurisdiction']).add_prefix('jurisdiction_')\n",
    "    df_court = json_normalize(df['court']).add_prefix('court_')\n",
    "    df_no_citations = df['citations'].apply(len)\n",
    "    df_first_citation = json_normalize(df['citations'].map(lambda x: x[0] if len(x)>0 else '')).add_prefix('citation1_')\n",
    "\n",
    "    cb = json_normalize(df['casebody'])\n",
    "\n",
    "    df_status = cb['status']\n",
    "    df_status = pd.DataFrame(df_status)\n",
    "    df_status.columns = ['cb_status']\n",
    "    df_no_attorneys = cb['data.attorneys'].apply(len)\n",
    "    df_no_attorneys = pd.DataFrame(df_no_attorneys)\n",
    "    df_no_attorneys.columns = ['cb_no_attorneys']\n",
    "    df_no_judges = cb['data.judges'].apply(len)\n",
    "    df_no_judges = pd.DataFrame(df_no_judges)\n",
    "    df_no_judges.columns = ['cb_no_judges']\n",
    "    df_no_parties = cb['data.parties'].apply(len)\n",
    "    df_no_parties = pd.DataFrame(df_no_parties)\n",
    "    df_no_parties.columns = ['cb_no_parties']\n",
    "    df_no_opinions = cb['data.opinions'].apply(len)\n",
    "    df_no_opinions = pd.DataFrame(df_no_opinions)\n",
    "    df_no_opinions.columns = ['cb_no_opinions']\n",
    "\n",
    "    df_first_attorneys = cb['data.attorneys'].map(lambda x: x[0] if len(x)>0 else '')\n",
    "    df_first_attorneys = pd.DataFrame(df_first_attorneys)\n",
    "    df_first_attorneys.columns = ['cb_data_attr1_first_attorneys']\n",
    "    df_sec_attorneys = cb['data.attorneys'].map(lambda x: x[1] if len(x)>1 else '')\n",
    "    df_sec_attorneys = pd.DataFrame(df_sec_attorneys)\n",
    "    df_sec_attorneys.columns = ['cb_data_attr2_sec_attorneys']\n",
    "    df_third_attorneys = cb['data.attorneys'].map(lambda x: x[2] if len(x)>2 else '')\n",
    "    df_third_attorneys = pd.DataFrame(df_third_attorneys)\n",
    "    df_third_attorneys.columns = ['cb_data_attr3_sec_attorneys']\n",
    "    df_first_judge = cb['data.judges'].map(lambda x: x[0] if len(x)>0 else '')\n",
    "    df_first_judge = pd.DataFrame(df_first_judge)\n",
    "    df_first_judge.columns = ['cb_data_judge1']\n",
    "    df_sec_judge = cb['data.judges'].map(lambda x: x[1] if len(x)>1 else '')\n",
    "    df_sec_judge = pd.DataFrame(df_sec_judge)\n",
    "    df_sec_judge.columns = ['cb_data_judge2']\n",
    "    df_third_judge = cb['data.judges'].map(lambda x: x[2] if len(x)>2 else '')\n",
    "    df_third_judge = pd.DataFrame(df_third_judge)\n",
    "    df_third_judge.columns = ['cb_data_judge3']\n",
    "    df_first_party = cb['data.parties'].map(lambda x: x[0] if len(x)>0 else '')\n",
    "    df_first_party = pd.DataFrame(df_first_party)\n",
    "    df_first_party.columns = ['cb_data_party1']\n",
    "    df_sec_party = cb['data.parties'].map(lambda x: x[1] if len(x)>1 else '')\n",
    "    df_sec_party = pd.DataFrame(df_sec_party)\n",
    "    df_sec_party.columns = ['cb_data_party2']\n",
    "    df_third_party = cb['data.parties'].map(lambda x: x[2] if len(x)>2 else '')\n",
    "    df_third_party = pd.DataFrame(df_third_party)\n",
    "    df_third_party.columns = ['cb_data_party3']\n",
    "\n",
    "    # Merge different sub dataframes\n",
    "    df_output = df_output.join(df_volume)\n",
    "    df_output = df_output.join(df_reporter)\n",
    "    df_output = df_output.join(df_jurisdiction)\n",
    "    df_output = df_output.join(df_court)\n",
    "    df_output = df_output.join(df_no_citations)\n",
    "    df_output = df_output.join(df_first_citation)\n",
    "    df_output = df_output.join(df_status)\n",
    "    df_output = df_output.join(df_no_attorneys)\n",
    "    df_output = df_output.join(df_no_judges)\n",
    "    df_output = df_output.join(df_no_parties)\n",
    "    df_output = df_output.join(df_no_opinions)\n",
    "    df_output = df_output.join(df_first_attorneys)\n",
    "    df_output = df_output.join(df_sec_attorneys)\n",
    "    df_output = df_output.join(df_third_attorneys)\n",
    "    df_output = df_output.join(df_first_judge)\n",
    "    df_output = df_output.join(df_sec_judge)\n",
    "    df_output = df_output.join(df_third_judge)\n",
    "    df_output = df_output.join(df_first_party)\n",
    "    df_output = df_output.join(df_sec_party)\n",
    "    df_output = df_output.join(df_third_party)\n",
    "    \n",
    "    # Extract the categories from the opinion field\n",
    "    for i in range(3):\n",
    "        print(i)\n",
    "        df_count = cb['data.opinions'].map(lambda x: format_text(x[i]['text']) if len(x)>i else '')\n",
    "        df_count = pd.DataFrame(df_count)\n",
    "        df_count.columns = ['dummy']\n",
    "        for keyword in keywords:\n",
    "            df_count_words = df_count['dummy'].map(lambda x: no_of_occurence2(x, keyword))\n",
    "            df_count_words = pd.DataFrame(df_count_words)\n",
    "            df_count_words.columns = ['cb_data_text_' + str(i) + '_' + keyword]\n",
    "            df_output = df_output.join(df_count_words)\n",
    "            \n",
    "    return(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over all extracted folders\n",
    "for folder in all_files:\n",
    "    filename = folder.replace('../data/01_download/', '')\n",
    "    if os.path.isfile('../data/02_processed_csvs/' + filename + '.csv'):\n",
    "        print(folder)\n",
    "        print('already processed')\n",
    "    else:\n",
    "        print(folder)\n",
    "        ## Each file is a jsonl file - each line is one json object\n",
    "        df = pd.read_json(folder + '/data/data.jsonl.xz', lines=True, compression='xz')\n",
    "        df_output = processDF(df)\n",
    "        df_output.to_csv('../data/02_processed_csvs/' + filename + '.csv', sep = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
